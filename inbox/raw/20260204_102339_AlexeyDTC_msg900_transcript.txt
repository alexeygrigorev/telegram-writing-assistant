---
source: telegram_voice
date: 2026-02-04T10:23:39+00:00
user_id: 822266080
username: AlexeyDTC
audio_file: 20260204_102339_AlexeyDTC_msg900.ogg
---

Про позицию AI-инженера. Вот у меня есть свое личное мнение, как эта позиция выглядит, и мне
интересно вот будет сравнить. Я сейчас как раз вот я делаю этот анализ, но прежде чем я сделаю
анализ, я хочу описать свое видение, и мне интересно насколько это видение отличается от того, что в
индустрии. В общем, мое видение такое, что AI-инженер это работа по интеграции AI в продукты.
Интеграция это может происходить, ну, как правило, чаще всего это вызов каких-то уже существующих
LLM, в смысле через LLM-провайдеры, то есть через OpenAI. То есть само взаимодействие с LLM, оно
чаще именно через LLM-провайдеры, то есть будь то OpenAI, Anthropic или какой-то еще. Реже селф-
хостинг и еще реже селф-хостинг каких-то зафайнтюнингных моделей То есть чаще именно использование
LLM, если то мы говорим про коробочные решения как сервиса Это по поводу использования LLM Дальше
работа состоит, ну как я сказал, в интеграции AI продуктов в ну я и в продукты какие-то в чем
собственно работа да то есть это ну есть продукт какой-то ну будь то не знаю marketplace и так далее
не нужно какую-то я и штуку есть то есть какие-то простые вещи которые делаются одним и пиай колом
на структуры структуризации информации например есть мы хотим чтобы пользователь не приходилось все
заполнять вручную они делают фотку они делают какое-то описание и все все заполняется автоматически
на основе этих данных цвета модель и прочее да тут по сути все вся работа состоит в том, чтобы
отправить запрос в OpenAI и получить его, ну, все правильно заполнить. То есть тут structure output,
но кажется, что это очень простая задача. На самом деле, как говорится, дьявол в деталях, что тут
очень много работы по prompt engineering. То есть правильное написание промпта, чтобы оно правильно
все экстрактило. плюс тут очень много эволюция то есть нужно чтобы мы когда выкатываем эту штуку на
большое количество пользователей нужно быть уверенным что там ничего не сломается и не будет каких-
то результатов для нас плохих то есть очень много нужно локально тестировать не на пользователях а
локально сначала то есть у нас есть какой-то промп у нас есть набор тестов в этих тестах мы просто
разные сценарии использования этой штуки прогоняем и смотрим, что они все проходят. Плюс у нас есть
эволюэйшн какой-то сет, который мы тоже делаем, как я инженеры. Вот. И на этом эволюэйшн сете мы
оцениваем все улучшения. То есть мы, допустим, подтыкали, поменяли как-то промпт, да? Действительно
ли этот промпт стал лучше или хуже стало? Вот. Насколько лучше стал экстракшн происходить? Ну, вот
такие вещи, да? prompt engineering prompt versioning production как пользователи пользуются, сколько
ошибок, как все хорошо парсится, какие-то крайние случаи рассматривать, то есть где модель не
работает как надо, собирать фидбэк от пользователей, то есть кнопочку сделать, чтобы пользователи
нажали, типа тут не сработало правильно. Фидбэк может быть implicit и explicit. Implicit это когда,
допустим, модель сделала неправильный цвет, выбрала, да, пользователь поменял цвет этот, то есть это
такой implicit feedback, что вывод нашей модели, он неправильный. Может быть explicit, да, то есть
сделать кнопочку, где пользователь нажал палец вниз, да, и описал в чем проблема. То есть на,
казалось бы, таком простом приложении, на таком простом примере про то, как интегрировать это в
продукт, можно описать, собственно, и роль AI-инженера, да? То есть это может быть и не AI-инженер
делает, но все эти вещи, которые я писал, я так вижу роль AI-инженера. И это мы рассмотрели только
простой случай. Если мы говорим про что-то сложное, типа рак, типа агентов, то тут в принципе
процесс тот же самый. Основные как responsibility, что люди должны делать, они те же самые. prompt
engineering, prompt versioning, testing, evaluation, monitoring, observability. Все это остается,
просто сложность возрастает. То есть если мы добавляем рак, то нам нужно уметь построить pipeline
для интеграции рака, для того чтобы собирать данные и складывать в наш knowledge base, Потом плюс
рак это достаточно такой устоявшийся паттерн, и его можно использовать не только для Q&A ботов, а
для много чего еще. То есть вот как раз находить эти возможности использования, где мы можем какую-
то внутреннюю базу знаний использовать для чего-то, кроме Q&A, тоже как раз роль AI-инженера. Ну и
последнее, агенты. Ну, с агентами все сложнее становится, потому что вместо одного запроса в OpenAI
у нас количество этих запросов растет. Тут нужно понимать про function calling, тут нужно понимать
про то, когда тулы должны использоваться, когда не используются они. вот ну как то есть мы хотим в
шов каких-то сценариях использовался ту в каких-то он не должен использовать все это мы должны уметь
прописать в тестах все это мы должны в эволюции на вывале еще не нашим как-то заметить и какие-то
метрики определить чтобы понимать как наш агент работает или нет или как наш рак работает или нет
вот так я вижу роль и я инженера поверхностно то То есть это для простых решений. То есть я описал
это на простом решении, но все становится сложнее, когда у нас появляются рак, агенты. Вот, то есть,
собственно, вот это все уметь делать. В этом я и вижу роль AI-инженера. Ну, то есть интегрироваться,
интегрировать AI в продукты так, чтобы они работали и чтобы мы были уверены в том, что они работают.
И чтобы мы могли принимать какие-то data-driven decisions. и чтобы мы всегда знали, что происходит.
То есть мы могли мониторить использование, могли мониторить косты наши. Ну, в этом я вижу роль.