---
title: "AI Engineer Webinar Q&A"
created: 2026-02-16
updated: 2026-02-17
tags: [ai-engineering, career, webinar, q-and-a]
status: draft
---

# AI Engineer Webinar Q&A

After the "A Day in the Life of an AI Engineer" webinar, there were many questions that I didn't have time to answer live. The webinar went really well with a lot of engagement[^1]. I promised everyone I would answer these questions, so here they are[^1].

The questions are really good - things like how a data engineer can become an AI engineer, and other career-related topics[^1].

## Questions Answered Live During the Webinar

These questions were answered during the live webinar session[^23].

### Data Engineer to AI Engineer Transition

Question: How can a data engineer transition to become an AI engineer?

For data engineers, it's primarily an engineering role, not a research or science role. Most "AI" work is just tweaking prompts and other engineering tasks. Data engineers already know tests, CI/CD, monitoring. The flavor might differ - data monitoring vs AI monitoring - but the tools are very similar. Data engineers already know how to collect logs[^23].

The specific skills to learn: how to interact with LLM providers, how to tune prompts, how to evaluate models. Since data engineers already have the engineering background, it's way easier. After 3-4 months of learning AI-specific testing and evaluation, a data engineer should be ready to transition[^23].

For RAG specifically, you need a search engine, which needs data, which needs an ingestion pipeline. This is what data engineers have been doing their entire career. As a data engineer, you can already join an AI team by contributing to data pipelines and gradually shift to more AI-related work[^23].

How relevant is data engineering in the AI era? Super relevant. Without data engineering, nothing will work. We still need data going into our search engines. There are so many things relevant for AI[^23].

### Interview Preparation Focus

Question: How to narrow down what to focus on when preparing for interviews in terms of topics?

The most important parts to focus on:
1. Learn how to interact with LLM APIs
2. Understand how to create agents - LLMs with tools. Tools are everything, all the actions that LLMs can do
3. Know about RAG - it's the foundation for many, many AI applications
4. Testing - how to test your agents, how to make sure they behave the way you want
5. Monitoring - AI-specific monitoring aspects
6. Evaluation - this is the most important part[^23]

I cover all of this in [my course](https://maven.com/alexey-grigorev/from-rag-to-agents). This covers the most important 20% that accounts for 80% of the work[^23].

For projects: pick a specific domain, like e-commerce or online classifieds. Go to their website, see what problems they solve, think about how to solve them, and create a small project showing you can do it. Do this multiple times, then go to interviews and talk about these projects[^23].

You can already figure out what to focus on from job descriptions alone. A more detailed data-driven answer will come at the next webinar with job description analysis and interview examples[^23].

### AI Automation Specialists vs AI Engineers

Question: Why do people who are AI automation specialists call themselves AI engineers? What is the difference?

This might refer to QA engineers who automate testing, or people using tools like N8N or Zapier with LLMs. I wouldn't necessarily call them AI engineers in the terms I described today[^23].

Since the role is new and there is no strict definition, anyone can call themselves AI engineers and be partially correct. What I presented is my personal view, and these people who are AI automation specialists might disagree[^23].

But are they engineers? In my opinion, not really. If they do just clicking, there is no engineering rigor, no best engineering practices, no tests - without that, I wouldn't call myself an engineer. But it's just me. Maybe the title sounds cooler. AI automation with tools like N8N is still pretty cool though[^23].

### Good Backgrounds for AI Engineers

Question: What do you see as past experiences of active and impactful AI engineers - previous jobs as software engineers, data scientists, ML engineers?

Data scientists and ML engineers are excellent future AI engineers. I worked as a data scientist and spent a lot of time evaluating and deploying models. When I deploy models, most of the things I talked about in the presentation also apply to ML engineers. You just replace a call to OpenAI with a call to a locally hosted model, and the rest is the same[^23].

Data scientists are less focused on engineering - they would need to work on the engineering side. ML engineers are more focused on engineering but would need to work on the evaluation side. For ML engineers, it's probably the easiest transition[^23].

For any engineer: you know engineering best practices, you know testing. Software engineers are the best target audience for my course because you already know how to program, write tests, and many other things. It's way easier to start with an engineering background and add AI on top of that, rather than start with a research background and add engineering on top[^23].

Even though my title was data scientist, I called myself an engineer all the time because my focus was always on deploying models, on MLOps. You need to be a builder - know how to build things reliably. Generalists make good AI engineers. If you know how to do many things, not necessarily at an expert level, but a bit of everything, you'll be a good AI engineer[^23].

### Is Traditional NLP Legacy Tech?

Question: Is traditional NLP/ML engineering now effectively legacy tech?

Probably yes. gpt-4o-mini is insanely cheap. In my course, I use gpt-4o-mini and I haven't managed to spend a dollar yet. For structured text processing, it's nearly free. The effort calculation is obvious: how much effort do you need for traditional NLP models versus just sending your stuff to gpt-4o-mini?[^23]

There are probably still some cases where traditional NLP makes sense. Simple cases like a spellchecker. Or in search, when you have a typo, you still want to retrieve results, and you don't want to add extra latency - search needs to be very fast. But in general, the answer is clear[^23].

### Future of Engineering Roles as AI Gets Smarter

Question: What do you think about the future of software engineering, data science, and even AI engineering roles as AI is getting smarter each day?

I saw a post on Twitter today. Somebody asked: why does Anthropic have so many open software engineering positions if Claude is good at everything? The creator of Claude Code answered that somebody still needs to check the output, interact with it, give proper instructions, and check the results[^23].

Just today, I was working with Claude Code. I asked it to fix a bug. It fixed it, then I said run tests. Two tests were broken. It said "this is a pre-existing thing, not my fault, I don't want to deal with this." I said "but it is, because this is directly related to what we just changed." It apologized and said "yes, you're right." Then it proceeds to fix the test by completely deleting the old test and creating a new one. I asked "wait, why did you delete this test?" It came up with some excuse. I said "this new test is good, but add the old test back and make sure it passes." It reluctantly did it[^23].

They are sometimes sneaky and lazy. This was Opus 4.6 - the best coding model we have. It tried to cover up that it didn't want to fix my test. It's like a very enthusiastic intern - they can work really well, but sometimes they're sloppy and we need to look after them[^23].

I don't think engineering is in danger. We still need to watch after AI, we still need to enforce best engineering practices. Without that, AI will create something that doesn't work and is dangerous. So basically, engineers are safe[^23].

With data science, maybe not so sure. For simple things, GenAI kind of replaces a data scientist to some extent. Data scientists who don't really do engineering - if they get laid off, it's not so easy for them to find a job[^23].

## Questions Answered After the Webinar

These questions were submitted via Slido and answered offline after the webinar[^2].

## AI Architect vs AI Hobbyist

Question: What specific technical evidence or "proof of work" makes a candidate stand out as a legitimate Architect rather than just an AI hobbyist?[^2]

First, these terms are not very concrete. What is an architect? I don't know. What is an AI hobbyist? I also don't know. Is an AI hobbyist someone who learned to run N8N, or something more?[^3]

For example, I can do something in a notebook and run it, and it already solves some problems. I see nothing wrong with that - it's actually great. Many things I personally do with AI are these small mini-projects that do something. For instance, I run Claude Code and it automates something for me, saving a lot of time. It's personally super useful. Can you call me an AI hobbyist? Maybe[^3].

I won't speak about architects specifically, so let me answer about AI engineers instead. How do you tell an AI hobbyist from an AI engineer? I already talked about this during the presentation when we discussed NIT and other things[^3].

The difference between an engineer (any engineer) and a non-engineer: engineers know and follow best engineering practices. Tests are familiar to them, they know how to do them. All the best practices around tests, data-driven decisions - they have all of that. Monitoring is a must. They know how to collect feedback[^3].

For a non-engineer or hobbyist - when I do something for myself, it's not a product. I don't have a good test suite, I don't have good monitoring. And that's fine. For my personal use I don't need it. I can just run it, see if it solves the problem, great. If not, I adjust it for myself. I don't need to write some big comprehensive solution. But if I worked at a company integrating an AI product, that's when you need all of it. That's the difference between an AI engineer and an AI hobbyist[^3].

As for architects - that's a vague concept. Architects deal with things like caching, building flows from components. This architecture is not drastically different whether you're building ML systems, AI systems, or regular software engineering systems. If you take a traditional software architect who knows a bit about ML and AI, they're essentially a ready-made AI architect. I haven't personally met such people, but I can roughly understand what this is - someone who comes to a client, designs how the system should look, and someone else implements it. Or in a company, they have a very high-level overview of everything happening[^3].

## AI Engineer Job Uniformity and Top Skills

Question: How uniform/similar are AI Engineer job posting descriptions and requirements? What would be the top 3 must-have skills common across all these postings?[^2]

I will answer this at the next webinar, which will be about the definition of the job. I looked at a lot of positions and extracted this data-driven from the freshest positions available. I'll add a screenshot with useful information. But we'll discuss all of this at the next webinar. I'll do the main part of the presentation that I planned, but I'll spend most of the time answering your questions[^4].

## Advice for New Graduates

Question: What should a recent or new grad focus on in order to break into this role?[^2]

Projects. You need to do as many projects as possible. I've talked many times about how to choose projects - I should probably record a separate article about this, that's a good idea. Do projects in the areas of AI that interest you, and based on that, go to interviews[^5].

Also important: networking, knowing people who are hiring, attending meetups - all of this helps. But the main focus should be on projects[^5].

Right now many people know how to make a request to OpenAI, but not everyone knows about testing and evaluation. This is where I think new graduates can really differentiate themselves[^5].

## Bayesian ML with Hybrid LLM Approach

Question: As a CEO, what does the investment and resource pipeline look like when taking a Bayesian ML approach combined with a hybrid LLM approach?[^2]

I don't know how to answer this question - I need more data. This is complex. This would require a [one-on-one consultation](https://alexeygrigorev.com/services/consulting.html) to figure everything out[^6].

## Data Engineering vs AI Engineering

Question: Data Engineering vs AI Engineering - where will there likely be more stable market demand (more positions), and which is more remote-friendly?[^2]

For stability, data engineering has been growing steadily. Right now I see that for many data scientists, finding work has become much harder than before. Data engineers haven't had this problem. They continue to be in demand - there's always a need to build pipelines[^7].

As for remote-friendliness, I don't have the data. I would scrape job postings and look. You could actually make a project out of this if you're interested - scrape the data and analyze it. I noted this down as a post idea. We could look into this sometime. I also noted another post idea: how to select a portfolio project[^7].

## AI Engineer vs Traditional Developer

Question: AI Engineer title vs traditional Developer title - are they essentially the same except for prompt versioning? There seems to be a lot of overlap.[^2]

I'll assume "traditional developer" means a regular software engineer - a generalist who can do pretty much anything. Typically they have more focus on backend and databases, less on frontend. But as a rule, software engineer generalists can do everything, including AI. Adding AI to their already wide skill set is not that much extra[^8].

I agree the overlap is very large. As I said, an AI engineer is first and foremost an engineer. The AI part comes second. Just like Data Engineer, ML Engineer, and all other engineers - these are all engineers first, specialists second[^8].

The software engineering overlap is significant. But there are some AI-specific things: prompt engineering, prompt versioning, model tuning, and tests that are somewhat specific to AI. Evaluation is also specific to AI. Evaluation is closer to what data scientists do than anyone else. For data scientists, evaluation is a very familiar concept. For software engineers, evaluation takes a few times of doing it before it clicks. But it's not rocket science - all of this can be learned[^8].

Realistically, you can take a software engineer and make them a ready AI engineer in two to three months. That's why in my course, the ideal target audience is a software engineer who already has all these skills with testing and everything else. I just show them specifically how these skills apply to AI. And that's it - a ready AI engineer at the output[^8].

## Transitioning from Telecom Engineering

Question: With 20 years as a telecom engineer (EEE background), no coding background, now learning Python, LLMs & agentic AI - must I first become a Data Scientist/Software Engineer to be a proficient AI Engineer?[^2]

Becoming a data scientist first - no, that won't help. But becoming a software engineer - yes, that would help. But this doesn't mean you can't start with AI. You can start right there[^9].

The main thing right now is to learn Python and learn things like testing that I talked about during the webinar. I would start with Python - general things applicable everywhere, not specifically to AI. I'm actually preparing a course about this, so stay tuned[^9].

From there, move into AI engineering and focus on projects. Do as many projects as possible. The more projects, the better. When you don't have real work experience, you can create surrogate experience by inventing your own projects[^9].

Start applying for jobs right away while learning. For example: learn Python, take the engineering course, and start applying for jobs in parallel. Initially they probably won't call you back, but you should still do it. And alongside this, keep working on as many projects as possible[^9].

By trying to become a better AI engineer, you also become a better software engineer[^10]. If attempts to find AI engineering work don't lead anywhere, you can also look for software engineering jobs in parallel. There are typically many more software engineering positions than AI engineering ones, so it might be easier to find one[^10].

You should also learn to use AI tools and assistants like Claude Code, GitHub Copilot, and similar tools. They really help with becoming a generalist and leveling up software engineering skills. I want to make a course about this approach too[^10].

So do projects - some connected to AI, some general purpose. I'd suggest roughly 50/50 split. Software engineering skills will be useful in your career regardless. Even if the AI engineer position bubble bursts in a few years - we don't know what the future holds - good software engineers will always be needed. Especially those who can manage AI agents rather than be replaced by them[^10].

## Practical Evaluation Tools

Question: Can you share some practical instruments for evaluation?[^2]

The best tool is the one you write yourself, based on your specific needs. But in general, Evidently is very good. I like Evidently, but there are quite a few options out there. It's hard to recommend just one, but I'd recommend Evidently[^11].

Given that we have so many capabilities now, it's very easy to build something from scratch yourself. I would start from what you specifically need. If you can't find a ready-made solution in a library, you can build it yourself[^11].

How to build it yourself? I show this in my course, and the course also uses Evidently. But the general approach: first you do it in Excel - just prepare a dataset. Then you run it in Python with pandas or similar tools. Then you move it to CI/CD. We do these steps in the course. The CI/CD part we might not do, but I might add it - it's not that complex[^11].

The key insight: writing your own evaluation tools is not that hard, because all these AI assistants are available and ready to write something quickly at your request[^11].

## Building an Engineering Team for Trova

Question: If you were launching Trova - what would your engineering team look like? Who would do what?[^2]

Let's start with the fact that Trova is a project I made in 15 minutes. If I wanted to develop it further, here's what I'd do[^12].

First, I'd work alone for several months and see if it's even viable. Does it bring in any money? Can I earn from it? If it doesn't solve any user problems and doesn't solve my problems, I stop working on it. If it solves my problems - good, at least I continue using it myself, but not as a main focus. If customers start appearing, I invest more[^12].

When there are many customers, I can afford to hire the first person. I'd hire a software engineer generalist and give them a Claude Code Pro subscription (costs around 180-200 euros). This person would take over my responsibilities. I'd focus more on vision while the person works full-time on the project[^12].

As the project grows, the next hire would be a frontend engineer. At some point everything will need to be rewritten - the frontend person handles that. Some AI features I can do myself, some maybe an intern can do[^12].

I think two people can sustain growth for quite a while. After that, I'd probably keep hiring backend engineers. Initially I'd provide the business vision myself, but after some time I'd need a product manager to talk to users and decide what to work on. This might be the third hire, or maybe later - depends on how quickly I get tired of doing it myself[^12].

I probably wouldn't hire AI engineers very soon, because most of the work is engineering work. A startup doesn't need specialists - a startup needs generalists[^12].

Later, when the company grows to maybe 50-60 people and there's role specialization, then you'd need someone purely focused on AI. That's when you can hire an AI engineer. But it depends on the project. Some projects need deep AI expertise from the start[^12].

The bottom line: focus on generalists. If the project is AI-first, then maybe one of the first hires would be an AI engineer. Otherwise, it would be generalists, frontend developers, and business people or product managers[^13].

## Monitoring for AI Engineers

Question: Do AI engineers need to do data monitoring, or is monitoring model outputs sufficient?[^2]

Data monitoring is generally important, but specifically in the work of an AI engineer, it might be less critical. But it depends on context. If we're talking about RAG and we have a database that the agent accesses, then naturally it's important that the data in that database is good[^14].

In other cases, monitoring is not just about outputs - it's about everything: all function calls, costs, the health of the microservice. You can't limit yourself to just data monitoring or just output monitoring. You need to do everything comprehensively[^14].

## Product Engineers and AI

Question: Are product engineers expected to also be AI engineers?[^2]

Honestly, I don't know exactly what a product engineer is. From what I've heard and understood, product engineers are people who have both good product sense and are qualified engineers. They still have some specialization - they're not just super-generalists. So yes, they can be product engineers with an AI focus, why not[^15].

As for the expectations, I can't answer precisely because I've never worked with product engineers, never hired them, and don't have acquaintances with that title[^15].

But I'll add: product sense is a very useful skill for any engineer. I don't have a precise definition of product engineers. But I think for any engineer, especially at the senior level, this skill is essential. Not just doing whatever, but understanding exactly what impact your work has, what metrics you're optimizing, what product metrics you're optimizing[^16].

For example, you optimize latency not because it's a cool engineering challenge, but because you understand how it leads to increased revenue or improvement of a critical business metric. This is a useful skill for any engineer, including AI engineers. I think all engineers should have product sense and business understanding, especially seniors[^16].

## Critical Non-Technical Skill for AI Systems

Question: What is the most critical non-technical skill required to lead and govern AI systems in a production environment?[^2]

I don't really know the answer - I don't have much experience in this specific area. I'm not sure what "govern AI systems" means exactly. Is it about compliance? About tracking where data goes?[^17]

It depends on the specific situation. But as a rule, for all such things: stakeholder management, product sense that I mentioned, business understanding - these are all important. Being able to listen to people who tell you what's important, understand why it's important, and translate their requirements into code[^17].

I realize this is a very generic answer. I don't have a better one. If you want something more specific, describe a concrete problem you're trying to solve, and we can think more specifically about it[^17].

### Community perspective on governance

This question came up again in a separate conversation. Governance in the context of large, slow-moving companies means having checkboxes that everything is verified and secured, with processes controlled by someone. There are specific people and roles within the company responsible for this[^24].

Lena's answer: understand the domain to understand the risks, not just in a vacuum. You need domain knowledge to properly assess what risks exist and how to mitigate them[^24].

<figure>
  <img src="../assets/images/ai-engineer-webinar-qa/governance-discussion.jpg" alt="Telegram conversation about governance in AI systems">
  <figcaption>Discussion about governance - Lena suggests understanding the domain to understand risks</figcaption>
  <!-- Screenshot showing the community conversation where governance is explained and Lena provides her perspective -->
</figure>

## Frontend Engineers Transitioning to AI

Question: How can frontend engineers transition into AI engineers?[^2]

Frontend engineers follow a similar path as other engineers. As I explained during the main talk, AI engineers focus more on the backend, so frontend engineers would need to build up their backend skills[^18].

For technologies: instead of Python, it's perfectly fine to use TypeScript. I see TypeScript used a lot in AI engineering right now. So you can exist entirely in the TypeScript ecosystem, and there are plenty of jobs that require TypeScript. There are plenty of projects built in TypeScript too[^18].

From frontend, you can easily transition to full stack. Do backend in TypeScript. Once you have backend and full stack experience, add everything we discussed during the lecture. Your advantage over other engineers: they can't do what you can - you can close the entire full stack end-to-end, from writing the backend to integrating it into the product. When we talked about who to hire first for a team, a full stack person is probably the best candidate[^18].

Don't forget about AI tools. I recommend starting with something like Cursor, or go straight to Claude Code - pick any AI assistant and try doing backend with its help. Once backend clicks, start learning AI. And that's it - you're a ready AI engineer after some time. The main focus should be on projects. That's the most important thing[^18].

## The Data Scientist Role

Question: Why is the Data Scientist role considered outdated? Was this based on job market observations?[^2]

I don't remember exactly how I phrased it during the presentation. I don't think I said it's completely outdated. But based on what I see, for some of my acquaintances in data science positions, finding work has become much harder than before[^19].

I'm a data scientist myself, so this is somewhat of an alarming signal. If I had to look for work, how easy would it be?[^19]

Why is this happening? I think because a lot of data science work is now very easy to automate. If you take an AI engineer and give them a Claude Code subscription, they'll figure out all the data science stuff very quickly. Plus AI engineers usually have some ML background, so it's not hard for them[^19].

If we're talking about data scientists who focus purely on modeling - in a first approximation, if we're not talking about very complex problems, a lot of this is now solved with AI. You just take an assistant and it trains an XGBoost model with good metrics for you[^19].

If a data scientist has Kaggle skills and knows some things well, they won't disappear. I can't say the role is completely outdated. If you add the AI engineering skills I talked about today, you can continue working fine[^19].

AI engineers and data scientists often work in the same teams - the teams that work with AI products. Where there are no AI engineers, data scientists typically cover those AI engineering needs. If we take a classic team with a data engineer and data scientist but no AI engineer, and they need to integrate an AI solution, those two can figure it out together without problems. It's not rocket science, and the skills needed are skills these people already have[^19].

But data scientists who can only do analytics, only train models, and don't go beyond notebooks - the trend is that it's been hard for them for quite a while already[^19].

As I showed during the webinar, right now a single request to OpenAI can replace many tasks. So the tasks where you still need traditional modeling have become much fewer[^19].

I can't say the role is dying completely, because I know data scientists who are doing just fine in data science positions[^20]. But even before AI appeared, the trend was that data scientists need to know a lot. Full-stack data scientists and generalists have never had problems finding tasks that match their skills, and likely never will. Whatever they're called - data scientist, AI engineer - they can do anything and adapt quickly to new things[^20].

Being a generalist overall but with a specialization in some area is useful. For me, I consider myself a generalist with a focus on AI and data - I was a data science generalist. I don't think these skills are going away[^20].

There are still many tasks involving traditional ML. In large companies where there is role specialization, tuning models with specific constraints still needs traditional approaches. Take pricing, for example - you can't predict a car price using just GPT, or rather, it won't work well. For such tasks you still need traditional ML[^20].

There are quite a few tasks where traditional ML is still needed. As for how the AI engineering trend will go - we don't know. If you have engineering understanding and engineering principles, you'll always find something to do. But if you're a classic data scientist who can only stack XGBoost and nothing else, then finding work might be a problem[^20].

I know several very good specialists here in Berlin who are good data scientists but struggled to find work for a long time. The market right now is such that it can be hard for everyone[^21]. So: stay informed, keep doing projects, try to remain as employable as possible, learn AI assistants, and keep improving constantly[^21].

## Sources

[^1]: [20260216_182231_AlexeyDTC_msg1789_transcript.txt](../inbox/used/20260216_182231_AlexeyDTC_msg1789_transcript.txt)
[^2]: [20260216_182412_AlexeyDTC_msg1791.md](../inbox/used/20260216_182412_AlexeyDTC_msg1791.md)
[^3]: [20260216_182922_AlexeyDTC_msg1793_transcript.txt](../inbox/used/20260216_182922_AlexeyDTC_msg1793_transcript.txt)
[^4]: [20260216_183023_AlexeyDTC_msg1795_transcript.txt](../inbox/used/20260216_183023_AlexeyDTC_msg1795_transcript.txt)
[^5]: [20260216_183131_AlexeyDTC_msg1797_transcript.txt](../inbox/used/20260216_183131_AlexeyDTC_msg1797_transcript.txt)
[^6]: [20260216_183210_AlexeyDTC_msg1799_transcript.txt](../inbox/used/20260216_183210_AlexeyDTC_msg1799_transcript.txt)
[^7]: [20260216_183357_AlexeyDTC_msg1801_transcript.txt](../inbox/used/20260216_183357_AlexeyDTC_msg1801_transcript.txt)
[^8]: [20260216_190324_AlexeyDTC_msg1803_transcript.txt](../inbox/used/20260216_190324_AlexeyDTC_msg1803_transcript.txt)
[^9]: [20260216_190526_AlexeyDTC_msg1805_transcript.txt](../inbox/used/20260216_190526_AlexeyDTC_msg1805_transcript.txt)
[^10]: [20260216_191034_AlexeyDTC_msg1807_transcript.txt](../inbox/used/20260216_191034_AlexeyDTC_msg1807_transcript.txt)
[^11]: [20260216_191203_AlexeyDTC_msg1809_transcript.txt](../inbox/used/20260216_191203_AlexeyDTC_msg1809_transcript.txt)
[^12]: [20260216_191932_AlexeyDTC_msg1811_transcript.txt](../inbox/used/20260216_191932_AlexeyDTC_msg1811_transcript.txt)
[^13]: [20260216_191932_AlexeyDTC_msg1812_transcript.txt](../inbox/used/20260216_191932_AlexeyDTC_msg1812_transcript.txt)
[^14]: [20260216_192129_AlexeyDTC_msg1815_transcript.txt](../inbox/used/20260216_192129_AlexeyDTC_msg1815_transcript.txt)
[^15]: [20260216_192359_AlexeyDTC_msg1817_transcript.txt](../inbox/used/20260216_192359_AlexeyDTC_msg1817_transcript.txt)
[^16]: [20260216_193037_AlexeyDTC_msg1819_transcript.txt](../inbox/used/20260216_193037_AlexeyDTC_msg1819_transcript.txt)
[^17]: [20260216_193812_AlexeyDTC_msg1821_transcript.txt](../inbox/used/20260216_193812_AlexeyDTC_msg1821_transcript.txt)
[^18]: [20260216_194341_AlexeyDTC_msg1823_transcript.txt](../inbox/used/20260216_194341_AlexeyDTC_msg1823_transcript.txt)
[^19]: [20260216_195304_AlexeyDTC_msg1825_transcript.txt](../inbox/used/20260216_195304_AlexeyDTC_msg1825_transcript.txt)
[^20]: [20260216_195702_AlexeyDTC_msg1827_transcript.txt](../inbox/used/20260216_195702_AlexeyDTC_msg1827_transcript.txt)
[^21]: [20260216_222017_AlexeyDTC_msg1829_transcript.txt](../inbox/used/20260216_222017_AlexeyDTC_msg1829_transcript.txt)
[^22]: [20260217_065728_AlexeyDTC_msg1831_transcript.txt](../inbox/used/20260217_065728_AlexeyDTC_msg1831_transcript.txt)
[^23]: Webinar recording: "A Day in the Life of an AI Engineer" (2026-02-16)
[^24]: [20260217_092842_AlexeyDTC_msg1889_transcript.txt](../inbox/used/20260217_092842_AlexeyDTC_msg1889_transcript.txt), [20260217_092832_AlexeyDTC_msg1887_photo.md](../inbox/used/20260217_092832_AlexeyDTC_msg1887_photo.md)
