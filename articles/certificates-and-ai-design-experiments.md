---
title: "Certificates and AI Design Experiments"
created: 2026-02-01
updated: 2026-02-16
tags: [certificates, ai-design, automation, gemini, claude-code]
status: draft
---

# Certificates and AI Design Experiments

## Creating Workshop Certificates

After conducting the two-day workshop "Build Your Own AI Coding Assistant from Scratch" at NOW-GMBH in Berlin on January 19-20, 2026, participants requested certificates[^1].

This was a good opportunity to create promotional material that participants would share on social media, potentially driving traffic to future workshops. The certificate includes a link to my website, so when shared on LinkedIn, people can click through and learn about upcoming workshops.

## Initial ChatGPT Certificate Creation

Before automating the certificate process, I first experimented with creating a certificate using ChatGPT directly as an image generation tool. I wanted to see what it could produce[^5].

The process started with taking a screenshot from the AI Buildcamp course website on Maven to get the visual style, then asking ChatGPT to create a certificate in that style[^6].

### First Attempt: AI Buildcamp Style

I took a screenshot from a course (noted the background) and told ChatGPT to create a certificate in the same style. I initially wanted it to match the course aesthetic exactly[^7].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/chatgpt-certificate-first-attempt.jpg" alt="First ChatGPT certificate attempt">
  <figcaption>First certificate generated by ChatGPT in AI Buildcamp style</figcaption>
</figure>

### Second Attempt: Maven Style

I then took a screenshot from Maven (which has a new design) and asked ChatGPT to create a certificate in that style. I specifically asked to remove the seal and Maven logo[^8].

This result looked very good and I wanted to replicate something similar.

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/maven-style-reference-and-result.jpg" alt="ChatGPT certificate in Maven style">
  <figcaption>Certificate generated by ChatGPT inspired by Maven's design</figcaption>
</figure>

### Limitations of Image Generation

While the ChatGPT-generated images looked good, there was a fundamental problem: I couldn't edit them. If I wanted to change a name from a placeholder to an actual person's name, I couldn't do it with the generated image.

For automation, I needed something editable - HTML and CSS that I could programmatically modify. This is why I moved to trying to convert the ChatGPT design into HTML/CSS with Claude's help[^9].

This was a good opportunity to create promotional material that participants would share on social media, potentially driving traffic to future workshops. The certificate includes a link to my website, so when shared on LinkedIn, people can click through and learn about upcoming workshops.

### Current Certificate Generation Workflow

For DataTalks.Club courses, I use an HTML template created by a designer. The process:
1. Use HTML/CSS template with placeholders
2. Replace placeholders with actual values (name, date, etc.)
3. Use Chromium (via browser automation) to render the page
4. Save as PDF

This approach works well and has been used for existing course certificates[^2].

## Part 1: Manual Certificate Recreation

### ChatGPT Initial Certificate

For the workshop certificates, I wanted to have a similar process, so I needed an HTML+CSS template too.

I took a screenshot of the AI Buildcamp course website from Maven and asked ChatGPT to generate a certificate image following the same visual style[^1].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/chatgpt-reference-certificate.jpg" alt="Certificate generated by ChatGPT">
  <figcaption>Initial certificate created by ChatGPT (this is the image we want to reproduce with CSS/HTML)</figcaption>
</figure>

### Extract Background Template

I asked ChatGPT to remove everything except the background, leaving just the gold border and design template[^2].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/blank-certificate-gold-border.jpg" alt="Certificate background template">
  <figcaption>Background template created by ChatGPT after removing fonts</figcaption>
</figure>

### Manual Certificate Recreation with Claude

Using the background template from ChatGPT, I worked with Claude to recreate the full certificate (with fonts and text) using HTML and CSS[^3].

This was an iterative process where I was in control the whole time. After each iteration, I would check the result and give feedback to Claude. We went through multiple rounds of adjustments - the position of elements needed fine-tuning, and I had to manually adjust spacing and alignment throughout.

One challenge was the font. I couldn't find the exact font used in the original certificate - the fonts I found were paid fonts. I tried to find the closest alternative from Google Fonts.

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/claude-html-certificate-final.jpg" alt="Certificate recreated by Claude">
  <figcaption>Certificate recreated by Claude using HTML+CSS on top of ChatGPT's background</figcaption>
</figure>

## Part 2: Automated Background Recreation (Claude + Gemini Flash)

The manual approach worked but required me to check each iteration and provide feedback. I had an idea: what if there was something else that could check the results and provide feedback automatically? What if an AI could compare the current attempt with the original and tell Claude what to fix?

This led to an experiment using Claude together with Gemini Flash for automated comparison and feedback.

I decided to re-create the background from the certificate using HTML+CSS. 

### The Experiment Setup

Claude's built-in image recognition doesn't work well for detailed design comparisons. I looked for alternatives and found Gemini Flash[^4].

The approach was simple: give the AI the reference image and the current CSS output, ask it to compare them, and iterate until the match is 10/10.

### Background Iterations

I ran the experiment in the background while working on other tasks. The agent made several iterations on recreating the background with the gold border and lined texture[^4].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/claude-css-background-first.jpg" alt="First background iteration">
  <figcaption>First background iteration created by Claude</figcaption>
</figure>

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/claude-css-background-final.jpg" alt="Background after several iterations">
  <figcaption>Final background using CSS+HTML only</figcaption>
</figure>

## Part 3: Automated Full Certificate Recreation (Claude + Gemini Flash)

Using the same setup from Part 2, I attempted to recreate the entire certificate including fonts and text.

I asked Claude to use Gemini to analyze the original certificate and create a detailed to-do list for recreating all elements.

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/certificate-analysis-terminal.jpg" alt="Terminal showing certificate analysis">
  <figcaption>Gemini analysis of certificate design with to-do list</figcaption>
</figure>

The first thing Claude did was dropping all the work on the background we did previously and re-created something very simple - not even remotely close to what we had. Thankfully, git allows recovery.

But eventually, the result wasn't bad:

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/automated-certificate-from-scratch.jpg" alt="First certificate recreation attempt">
  <figcaption>First attempt at recreating the full certificate - dropped background work, started from scratch</figcaption>
</figure>

At this point I noticed a problem: I had told the AI to iterate until it's a 10/10 match. The AI would stop when it thought it was 8/10, saying that's "close enough."

So I decided to a strict rubric to standardize the evaluation and define what "good enough" means[^6]. Without it, the AI would give scores like 8/10 or 9/10 even when results clearly didn't match.

In my opionion the match was 4/10, so I asked it to create a rubric and iterate until gemini returns a 4/10 result.

Once the rubric was defined, I switched to another task (AI Engineering Buildcamp course), and let it run unobserved. 

After many iterations, the AI evaluator created this and rated the result as 7/10 in similarity to the original.

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/certificate-7of10-result.jpg" alt="Certificate result rated 7/10">
  <figcaption>Full certificate recreation rated 7/10 by AI evaluator - not quite matching the original</figcaption>
</figure>

Not only it was awful, but also definitely not 7/10.

### The Evaluation Problem

A major issue emerged: using AI for design feedback proved unreliable. The evaluation AI would:
- Give contradictory feedback (background: "cool white" to "warm cream" to "too warm" back to "cool white")
- Suggest different colors each time (border: #C9B080, #B8860B, #D4AF37, #C0B283, back to #B8860B)
- Flip-flop on effects ("barely visible", "too prominent", "too faint", "too prominent")
- Rate similarity as 8-9/10 when the results clearly didn't match the reference[^6]

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/ai-feedback-failures.jpg" alt="AI evaluation feedback showing contradictions">
  <figcaption>AI evaluation feedback showing contradictory suggestions and the core problem</figcaption>
</figure>

Even after creating a strict rubric to standardize evaluation, the AI still rated poor results as 6-7/10 when they were visually far from the target[^7].

## Lessons Learned

### What Didn't Work

1. **AI evaluation is unreliable**: The comparison tool gave inconsistent measurements and suggestions each time, making convergence impossible[^6]

2. **Too much manual control needed**: I couldn't just say "make it beautiful" and walk away. The process required:
   - Debugging the AI's image analysis capabilities
   - Working with prompts and frontends
   - Understanding Gemini's limitations (Flash vs Pro)
   - Tracking API costs (which I didn't track properly)

3. **Contradictory feedback**: The evaluator would contradict itself, causing the code to jump back and forth without making real progress[^7]

4. **Context loss**: When moving from background work to full certificate, the agent discarded previous work instead of building on it[^5]

### What Did Work

- The early iterations without Gemini integration produced better results
- Running experiments in the background while working on other tasks
- Using git to recover from overwritten files
- The concept itself is promising, just needs refinement

### Current Status

The certificates are done and delivered. The experiment ran while I recorded course videos, with the AI working in the background. I'd check in periodically to see progress and provide guidance[^3].

While the goal of full automation wasn't achieved, the human-assisted approach works. The earliest iterations were actually better - quality degraded when I integrated Gemini for automated comparison[^7].

## Certificate Hosting Infrastructure

### Existing Infrastructure

DataTalks.Club already has a certificate hosting solution at `certificate.datatalks.club`. The workflow:
1. Generate certificates
2. Upload to AWS S3
3. Download through the website

However, this infrastructure is tied to DataTalks.Club courses. For workshops and courses outside the club (AI Hero, Maven courses), a separate solution is needed. Additionally, I didn't want to use the existing pipeline for non-DataTalks workshops and courses - I wanted a different deployment location and a process tailored specifically for standalone workshops and courses[^10].

The goal was to partially redesign the process to be targeted at workshops and courses that are not part of DataTalks Club[^10].

### Delegating Infrastructure Setup to AI

Setting up certificate hosting typically involves multiple steps that would take 2-3 hours:
- Configuring S3 buckets
- Setting up CloudFront for HTTPS delivery
- Configuring DNS settings at the domain registrar
- Troubleshooting and testing

By delegating this task to Claude Code, the setup time was reduced to 5-10 minutes. The workflow:
1. Gave Claude access to the S3 bucket and CloudFlare
2. Asked Claude to set up the infrastructure
3. Followed instructions to add DNS records at GoDaddy (the domain registrar)
4. Claude handled the CloudFront and HTTPS configuration
5. When something didn't work, Claude debugged and fixed it immediately

The key benefits of this approach:
- Speed: What previously took hours of research and troubleshooting was done in minutes
- Audit trail: All steps are documented in the chat
- Reproducibility: The conversation serves as documentation for future setups

This approach works well for infrastructure tasks where the goal is clear but the implementation details require research and trial-and-error[^2].

## Next Steps

I want to return to this project to create improved certificates for AI Buildcamp. Ideas for improvement:

- Try Gemini Pro instead of Flash for better analysis
- Improve the evaluation prompt to be more consistent
- Build an agent with memory that can reference previous prompts and avoid contradictory feedback
- Track API costs properly
- Consider whether this level of automation is worth the complexity vs. just giving direct feedback

The concept of converting images to code is valuable and I expect to return to it in a month or two when there's more time to refine the approach.

## Part 4: Certificate Recreation with Claude Opus 4.6

I saw a tip in Claude Code suggesting the frontend-design plugin for HTML/CSS work and decided to try the certificate recreation experiment again. This time with Opus 4.6, letting it read the reference images directly[^25].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/opus46-frontend-plugin-tip.jpg" alt="Claude Code showing frontend-design plugin suggestion">
  <figcaption>Claude Code tip about the frontend-design plugin that inspired the new attempt</figcaption>
  <!-- The plugin suggestion appeared while working on HTML/CSS and triggered another round of certificate experiments -->
</figure>

### Certificate Recreation Attempt

Opus 4.6 started by reading the reference images, analyzing the background and certificate layout, reading the signature SVG, and then creating a pure CSS certificate. The process took about 2 minutes with 60 seconds of thinking time[^26].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/opus46-certificate-cooking.jpg" alt="Claude Opus 4.6 working on certificate recreation">
  <figcaption>Claude Opus 4.6 analyzing references and creating the pure CSS certificate</figcaption>
  <!-- Shows the step-by-step process: reading references, analyzing layout, creating HTML -->
</figure>

The design analysis was accurate. It correctly identified all the background elements and typography details from the reference[^27].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/opus46-design-analysis.jpg" alt="Detailed design analysis of certificate elements">
  <figcaption>Opus 4.6 design analysis of the reference certificate - background and typography details</figcaption>
  <!-- Gemini also detected these elements well previously, so this is not unique to Opus -->
</figure>

The second iteration produced a reasonable result. However, it clearly peeked into the previous results from earlier experiments despite being asked to start from scratch[^28].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/opus46-certificate-second-iteration.jpg" alt="Second iteration of certificate recreation by Opus 4.6">
  <figcaption>Second iteration of the certificate - looks good but borrowed from previous work</figcaption>
  <!-- The model was asked to start from scratch but appears to have used context from prior experiments -->
</figure>

### Comparison with Original

Comparing the original ChatGPT certificate with the Opus 4.6 recreation side by side, the result was okay but it borrowed a lot from the previous work, making it hard to judge. I asked it to focus on the background only instead[^29].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/opus46-original-vs-recreated.jpg" alt="Side by side comparison of original and recreated certificates">
  <figcaption>Original (left) vs Opus 4.6 recreation (right) - close but borrowed from previous work</figcaption>
  <!-- Hard to judge the quality since it may have used context from earlier experiments -->
</figure>

### Background-Only Experiment

The background generation experiment continued with many iterations. After 44 iterations of background comparison screenshots, the results were not converging to anything meaningful - just randomly trying different approaches[^30][^31].

<figure>
  <img src="../assets/images/certificates-and-ai-design-experiments/opus46-background-44-iterations.jpg" alt="File explorer showing 44 background comparison iterations">
  <figcaption>44 iterations of background comparison - the experiment did not converge</figcaption>
  <!-- Shows bg-comparison-v2 through bg-comparison-v44, plus the certificate files -->
</figure>

<figure>
  <p>Video: Screen recording of background evolution across iterations (bg-comparison-evolution.mp4) - shows how the background changes randomly without converging</p>
  <figcaption>The background changes across iterations - not converging, just randomly trying things</figcaption>
  <!-- This video shows the progression of all 44 background iterations -->
</figure>

### Experiment Results

With Claude Opus 4.6 and the original instructions, the background could not be recreated successfully. The certificate recreation was close, but it peeked into previous results, so it is hard to judge the quality independently. The background iterations did not converge - they kept randomly trying different things without making progress toward the reference[^32].

## Community Question

Before building a custom solution for certificate design and hosting, I want to learn from others who may have solved this problem. Some existing options I'm aware of:
- Google design tools (haven't tried yet)
- Design tools from Lava
- Experiments with Banana for image generation followed by design conversion

If anyone has experience with certificate generation systems or knows of existing solutions that avoid reinventing the wheel, I'd like to hear about it[^1].

## Sources

[^1]: [20260201_062732_AlexeyDTC_msg762_transcript.txt](../inbox/used/20260201_062732_AlexeyDTC_msg762_transcript.txt)
[^2]: [20260201_063504_AlexeyDTC_msg767_photo.md](../inbox/used/20260201_063504_AlexeyDTC_msg767_photo.md)
[^3]: [20260201_063436_AlexeyDTC_msg766_transcript.txt](../inbox/used/20260201_063436_AlexeyDTC_msg766_transcript.txt)
[^3]: [20260201_063912_AlexeyDTC_msg774_transcript.txt](../inbox/used/20260201_063912_AlexeyDTC_msg774_transcript.txt)
[^4]: [20260201_080307_AlexeyDTC_msg788_photo.md](../inbox/used/20260201_080307_AlexeyDTC_msg788_photo.md)
[^5]: [20260201_081321_AlexeyDTC_msg790_photo.md](../inbox/used/20260201_081321_AlexeyDTC_msg790_photo.md)
[^6]: [20260201_104544_AlexeyDTC_msg798_photo.md](../inbox/used/20260201_104544_AlexeyDTC_msg798_photo.md)
[^7]: [20260201_110803_AlexeyDTC_msg802_transcript.txt](../inbox/used/20260201_110803_AlexeyDTC_msg802_transcript.txt)
[^8]: [20260201_112736_AlexeyDTC_msg810_transcript.txt](../inbox/used/20260201_112736_AlexeyDTC_msg810_transcript.txt)
[^9]: [20260201_113251_AlexeyDTC_msg812_transcript.txt](../inbox/used/20260201_113251_AlexeyDTC_msg812_transcript.txt)
[^10]: [20260201_115109_AlexeyDTC_msg822_transcript.txt](../inbox/used/20260201_115109_AlexeyDTC_msg822_transcript.txt)
[^11]: [20260205_121005_AlexeyDTC_msg933_transcript.txt](../inbox/used/20260205_121005_AlexeyDTC_msg933_transcript.txt)
[^12]: [20260206_151920_AlexeyDTC_msg995_photo.md](../inbox/used/20260206_151920_AlexeyDTC_msg995_photo.md)
[^13]: [20260206_151933_AlexeyDTC_msg996_transcript.txt](../inbox/used/20260206_151933_AlexeyDTC_msg996_transcript.txt)
[^14]: [20260206_151938_AlexeyDTC_msg997_photo.md](../inbox/used/20260206_151938_AlexeyDTC_msg997_photo.md)
[^15]: [20260206_151953_AlexeyDTC_msg998_transcript.txt](../inbox/used/20260206_151953_AlexeyDTC_msg998_transcript.txt)
[^16]: [20260206_151958_AlexeyDTC_msg999_photo.md](../inbox/used/20260206_151958_AlexeyDTC_msg999_photo.md)
[^17]: [20260206_152024_AlexeyDTC_msg1000_transcript.txt](../inbox/used/20260206_152024_AlexeyDTC_msg1000_transcript.txt)
[^18]: [20260206_152838_AlexeyDTC_msg1001_transcript.txt](../inbox/used/20260206_152838_AlexeyDTC_msg1001_transcript.txt)
[^19]: [20260206_152838_AlexeyDTC_msg1002_transcript.txt](../inbox/used/20260206_152838_AlexeyDTC_msg1002_transcript.txt)
[^20]: [20260206_152855_AlexeyDTC_msg1003_transcript.txt](../inbox/used/20260206_152855_AlexeyDTC_msg1003_transcript.txt)
[^21]: [20260206_151508_AlexeyDTC_msg991_transcript.txt](../inbox/used/20260206_151508_AlexeyDTC_msg991_transcript.txt)
[^22]: [20260206_151508_AlexeyDTC_msg992_transcript.txt](../inbox/used/20260206_151508_AlexeyDTC_msg992_transcript.txt)
[^23]: [20260206_151622_AlexeyDTC_msg993_transcript.txt](../inbox/used/20260206_151622_AlexeyDTC_msg993_transcript.txt)
[^24]: [20260206_151915_AlexeyDTC_msg994_transcript.txt](../inbox/used/20260206_151915_AlexeyDTC_msg994_transcript.txt)
[^25]: [20260215_052728_AlexeyDTC_msg1689_photo.md](../inbox/used/20260215_052728_AlexeyDTC_msg1689_photo.md)
[^26]: [20260215_052822_AlexeyDTC_msg1690_photo.md](../inbox/used/20260215_052822_AlexeyDTC_msg1690_photo.md)
[^27]: [20260215_053301_AlexeyDTC_msg1693_photo.md](../inbox/used/20260215_053301_AlexeyDTC_msg1693_photo.md)
[^28]: [20260215_055432_AlexeyDTC_msg1695_photo.md](../inbox/used/20260215_055432_AlexeyDTC_msg1695_photo.md)
[^29]: [20260215_060526_AlexeyDTC_msg1697_photo.md](../inbox/used/20260215_060526_AlexeyDTC_msg1697_photo.md)
[^30]: [20260216_080444_AlexeyDTC_msg1707_photo.md](../inbox/used/20260216_080444_AlexeyDTC_msg1707_photo.md)
[^31]: [20260216_081159_AlexeyDTC_msg1709.md](../inbox/used/20260216_081159_AlexeyDTC_msg1709.md)
[^32]: [20260216_081225_AlexeyDTC_msg1711.md](../inbox/used/20260216_081225_AlexeyDTC_msg1711.md)
